{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prevention study\n",
    "\n",
    "First we will be curating all of the datasets associated with the prevention study.  This includes the following\n",
    "- Microbiome data\n",
    "- Proteomics\n",
    "- Hormone data\n",
    "- Inflammation data\n",
    "\n",
    "The final files will be found under `processed_data` named\n",
    "- 1706_1145_otu_table.biom (otu_table)\n",
    "- 1706_1145_mapping.txt (hormone, inflammation, all of the other data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from biom import load_table\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mapping = pd.read_table('../original_data/1706_prep_1145_qiime_20160731-151247.txt')\n",
    "otu_table = load_table('../original_data/otu_table_prev.biom')\n",
    "inflammation_mapping = pd.read_excel('../original_data/inflammation_prevention.xlsx')\n",
    "hormone_mapping = pd.read_excel('../original_data/prevention_hormones_analysis.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "submapping = mapping.loc[mapping['body_site'] == 'UBERON:distal colon']\n",
    "remaining_mapping = mapping.loc[mapping['body_site'] != 'UBERON:distal colon']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we'll match up all of the IDs corresponding to the inflammation markers to the IDs \n",
    "in the mapping file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# rename column name so that it doesn't clash with the name in the original mapping file\n",
    "inflammation_mapping=inflammation_mapping.rename(columns = {'#SampleID':'orig_name'})\n",
    "\n",
    "submapping = pd.merge(submapping, inflammation_mapping, \n",
    "                      how='outer', on='orig_name')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we'll link the sample names found in the proteomics file, and add a column in the mapping file that matches\n",
    "to those sample names.\n",
    "\n",
    "EDIT:  We will refrain from doing this here, because the numbers in the sample indeces don't line up with the\n",
    "host_subject ids.  It is not clear exactly what proteomics samples originated from which pigs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# proteome_ids = proteome_table.ids(axis='sample')\n",
    "# index = list(map(lambda x: x.split('_')[1], proteome_ids))\n",
    "# proteome_ids = pd.DataFrame({'proteome_name': proteome_ids,\n",
    "#                              'host_subject_id':index})\n",
    "\n",
    "# pd.merge(submapping, proteome_ids, how='outer', \n",
    "#          on='host_subject_id')['proteome_name']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we'll add weight, feed and hormone information to the mapping file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hormone_mapping = hormone_mapping.rename(columns = {'Sample ID':'hormone_sample_name'})\n",
    "hormone_mapping['#SampleID'] = ['1706.DD%d.prev'%i for i in hormone_mapping.hormone_sample_name]\n",
    "submapping = pd.merge(submapping, hormone_mapping, how='outer', \n",
    "                      on='#SampleID')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is also important to note that some of the pigs were actually placed in separate cages.\n",
    "(see `Animal housing details.xlsx`).  Specifically all of the pigs between 1-50 were placed in a separate penn\n",
    "from all of the other pigs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mapping = pd.concat((submapping, remaining_mapping))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: 'applicable'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-677d023071b5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'week'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimepoint\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/mortonjt/miniconda3/envs/bio/lib/python3.5/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[1;32m   2218\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2219\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masobject\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2220\u001b[0;31m             \u001b[0mmapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2222\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/src/inference.pyx\u001b[0m in \u001b[0;36mpandas.lib.map_infer (pandas/lib.c:62658)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-677d023071b5>\u001b[0m in \u001b[0;36mtime\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;36m14\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'week'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimepoint\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 10: 'applicable'"
     ]
    }
   ],
   "source": [
    "def cage_number(x):\n",
    "    try:\n",
    "        if int(x) <= 50:\n",
    "            return '0'\n",
    "        else:\n",
    "            return '1'\n",
    "    except ValueError:\n",
    "        return 'NA'\n",
    "mapping['cage'] = mapping.host_subject_id.apply(cage_number)\n",
    "\n",
    "def potato_color(x):\n",
    "    if pd.isnull(x):\n",
    "        return 'Not applicable'\n",
    "    if x == 'Control_1':\n",
    "        return 'Control'\n",
    "    if x == 'Control_2':\n",
    "        return 'HCD'\n",
    "    if 'purple' in x:\n",
    "        return 'purple'\n",
    "    if 'white' in x:\n",
    "        return 'white'\n",
    "    else:\n",
    "        #raise ValueError('x (%s) is bad' % x)\n",
    "        return 'Not applicable'\n",
    "    \n",
    "mapping['color'] = mapping['treatment'].apply(potato_color)\n",
    "    \n",
    "def potato_processing(x):\n",
    "    if pd.isnull(x):\n",
    "        return 'Not applicable'    \n",
    "    if x == 'Control_1':\n",
    "        return 'Control'\n",
    "    if x == 'Control_2':\n",
    "        return 'HCD'\n",
    "    if 'baked' in x:\n",
    "        return 'baked'\n",
    "    if 'raw' in x:\n",
    "        return 'raw'\n",
    "    if 'chipped' in x:\n",
    "        return 'chipped'\n",
    "    else:\n",
    "        #raise ValueError('x (%s) is bad' % x)\n",
    "        return None\n",
    "        \n",
    "mapping['processing'] = mapping['treatment'].apply(potato_processing)\n",
    "\n",
    "def time(x):\n",
    "    if pd.isnull(x):\n",
    "        return np.nan\n",
    "    if x == 'Not applicable':\n",
    "        return np.nan\n",
    "    if x == 'Final':\n",
    "        return 14\n",
    "    else:\n",
    "        return int(x.split(' ')[1])\n",
    "\n",
    "mapping['week'] = mapping.timepoint.apply(time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, we have combined most of the metadata into a single file.\n",
    "\n",
    "__Some outstanding questions__\n",
    "1. What pigs did the proteomics samples originate from.  Because of this is, it is currently not possible to correlation proteomics with anything else.\n",
    "2. What are the actual proteomics ids?  Right now, they are only labeled numerically between 1 to 4000.\n",
    "3. Where exactly was the inflammation measured (here we assumed that it was measured from the distal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mapping.to_csv('../processed_data/1706_1145_mapping.txt', sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reversal Study\n",
    "\n",
    "\n",
    "First we will be curating all of the datasets associated with the prevention study.  This includes the following\n",
    "\n",
    "- Microbiome data\n",
    "- Inflammation data\n",
    "\n",
    "The final files will be found under `processed_data` named\n",
    "- 1706_1911_otu_table.biom (otu_table)\n",
    "- 1706_1911_mapping.txt (hormone, inflammation, all of the other data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mapping = pd.read_table('../original_data/mapping_jairam_reversal.txt')\n",
    "otu_table = load_table('../original_data/otu_table_rev.biom')  \n",
    "inflammation_mapping = pd.read_excel('../original_data/Reversal study inflammatory markers.xlsx')\n",
    "\n",
    "# includes weight, feed intake and some hormone data\n",
    "mapping_parameters = pd.read_table('../original_data/mapping_all_parameters.txt') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since there is no explicit timepoint variable we'll add one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def timepoint(x):\n",
    "    if 'Initial' in x:\n",
    "        return 'week 0'\n",
    "    else:\n",
    "        return 'week 5'\n",
    "mapping['timepoint'] = mapping.site_potato.apply(timepoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since there are a whole bunch of missing samples, we'll assign the inflammation values to the 3 main body sites."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "distal_mapping = mapping.loc[mapping['Ext_Desc']=='Distal_Colon']\n",
    "proximal_mapping = mapping.loc[mapping['Ext_Desc']=='Proximal_Colon']\n",
    "ileum_mapping = mapping.loc[mapping['Ext_Desc']=='Ileum']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "inflammation_mapping['#SampleID'] = ['DD%d'%i for i in inflammation_mapping['Pig ID #']]\n",
    "distal_mapping = pd.merge(distal_mapping, inflammation_mapping, how='inner',\n",
    "                          on='#SampleID').dropna(subset=['BarcodeSequence'])\n",
    "\n",
    "inflammation_mapping['#SampleID'] = ['ID%d'%i for i in inflammation_mapping['Pig ID #']]\n",
    "ileum_mapping = pd.merge(ileum_mapping, inflammation_mapping, how='inner',\n",
    "                         on='#SampleID').dropna(subset=['BarcodeSequence'])\n",
    "\n",
    "inflammation_mapping['#SampleID'] = ['PD%d'%i for i in inflammation_mapping['Pig ID #']]\n",
    "proximal_mapping = pd.merge(proximal_mapping, inflammation_mapping, how='inner',\n",
    "                            on='#SampleID').dropna(subset=['BarcodeSequence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mapping = pd.concat((distal_mapping, ileum_mapping, proximal_mapping), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll add on the weight and feed intake parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mapping = pd.merge(mapping, mapping_parameters, \n",
    "                   on=['#SampleID','BarcodeSequence','LinkerPrimerSequence', \n",
    "                       'Treatment', 'Potato'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we'll make this mapping file QIITA complaint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def body_site(x):\n",
    "    if x == 'Distal_Colon':\n",
    "        return 'UBERON:distal colon'\n",
    "    elif x == 'Ileum':\n",
    "        return 'UBERON:ileum'\n",
    "    elif x == 'Proximal_Colon':\n",
    "        return 'UBERON:proximal colon'\n",
    "    else:\n",
    "        return 'UBERON:feces'\n",
    "mapping['body_site'] = mapping.Ext_Desc.apply(body_site)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mapping['instrument'] = '454 GS FLX Titanium'\n",
    "mapping['center_name'] = 'CSU Fort Collins'\n",
    "mapping['center_project_name'] = 'Jairam Purple potatoes'\n",
    "mapping['library_construction_protocol'] = 'Samples sequenced with 515/80rbc primers for V4 of 16S rRNA'\n",
    "mapping['key_seq'] = 'TCAG'\n",
    "mapping['linker'] = 'GA'\n",
    "mapping['platform'] = 'LS454'\n",
    "mapping['run_prefix'] = 'GW1M5C'\n",
    "mapping['sequencing_meth'] = 'pyrosequencing'\n",
    "mapping['target_gene']='16S rRNA'\n",
    "mapping['target_subfragment'] = 'V4'\n",
    "mapping['altitude']=0\n",
    "mapping['common_name'] = 'pig gut metagenome'\n",
    "mapping['country'] = 'USA'\n",
    "mapping['depth'] = 0\n",
    "mapping['elevation'] = 1525\n",
    "mapping['env_biome'] = 'urban biome'\n",
    "mapping['env_feature'] = 'animal-associated habitat'\n",
    "mapping['host_common_name'] = 'pig'\n",
    "mapping['host_subject_id'] = mapping['Pig ID #']\n",
    "mapping['latitude'] = 40.58526\n",
    "mapping['longitude'] = -105.084423\n",
    "mapping['host_scientific_name'] = 'Sus scrofula'\n",
    "mapping['host_taxid']='9825'\n",
    "mapping['physical_specimen_location'] = 'U Penn'\n",
    "mapping['physical_specimen_remaining']='FALSE'\n",
    "mapping['public']='FALSE'\n",
    "mapping['required_sample_info_status']='completed'\n",
    "mapping['sex']='male'\n",
    "mapping['taxon_id']='1510822'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mapping.to_csv('../processed_data/1706_1911_mapping.txt', sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Some outstanding questions__\n",
    "1. Was there no hormone data collected for the reversal study?\n",
    "2. What pigs did the proteomics samples originate from.  Because of this is, it is currently not possible to correlation proteomics with anything else.\n",
    "3. What are the actual proteomics ids?  Right now, they are only labeled numerically between 1 to 4000.\n",
    "\n",
    "Also note that the original QIITA mapping file is missing a whole bunch of samples.\n",
    "While this new mapping file contains more samples, it doesn't have the same format as the sample ids in QIITA.\n",
    "But the sample ids in this new mapping file are consistent with the sample ids in the OTU table."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Potatoes\n",
    "\n",
    "The potato metabolite data is under `original_data/LCMS_potatoes.csv`.  \n",
    "\n",
    "__Some outstanding concerns__\n",
    "1. The feature finding was done via XCMS.\n",
    "2. Only positive mode was analysed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
